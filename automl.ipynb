{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment,Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import azureml.core\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "source": [
    "## Initialize Workspace and Create an Azure ML experiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "experiment_name = 'heart-failure-automl-experiment'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
    "dataset_key = \"Heart-Failure-Prediction-Dataset\"\n",
    "description_text = \"Heart Failure Prediction Dataset\"\n",
    "\n",
    "if dataset_key in ws.datasets.keys(): \n",
    "    found = True\n",
    "    dataset = ws.datasets[dataset_key]\n",
    "else:\n",
    "    # Create AML Dataset and register it into Workspace\n",
    "    dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv'\n",
    "    dataset = Dataset.Tabular.from_delimited_files(dataset_url)        \n",
    "    #Register Dataset in Workspace\n",
    "    dataset = dataset.register(workspace=ws,\n",
    "                                name=key,\n",
    "                                description=description_text)\n",
    "\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ]
  },
  {
   "source": [
    "## Create or Attach an AmlCompute cluster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Check if the compute target exists\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2', max_nodes=5)\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "source": [
    "## Training Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, random_state=0, test_size=0.2)\n",
    "print(train.head(3))\n",
    "print(train.shape)\n",
    "train.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "print(datastore)\n",
    "datastore.upload_files(files = ['./train.csv'])\n",
    "train = Dataset.Tabular.from_delimited_files(path = [(datastore,'train.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\" : 30,\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"primary_metric\": 'accuracy',\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    compute_target=compute_target,\n",
    "    training_data= train,\n",
    "    label_column_name=\"DEATH_EVENT\",\n",
    "    debug_log = 'automl_errors.log',\n",
    "    **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Submit your experiment\n",
    "remote_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run, fitted_automl_best_model = remote_run.get_output()\n",
    "best_automlrun_metrics=automl_run.get_metrics()\n",
    "print('Best Run Id:', best_run.id, sep='\\n')\n",
    "print('Best Run Accuracy:', best_automlrun_metrics['accuracy'], sep='\\n')\n",
    "print('Best Run Metrics:', best_run.get_metrics(), sep='\\n')\n",
    "print('Best Run Properties:', best_run.get_properties(), sep='\\n')\n",
    "print('Best Model:', best_run.properties['model_name'], sep='\\n')\n",
    "print('Fitted Automl Best Model:', fitted_automl_best_model, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primary_metric in best_automlrun_metrics:\n",
    "    metric=best_automlrun_metrics[primary_metric]\n",
    "    print(primary_metric,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Save the best model\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "joblib.dump(fitted_automl_best_model, filename='outputs/automl.joblib')\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model_name = best_run.properties['model_name']\n",
    "script_file_name = 'inference/score.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'Heart Failure Prediction AutoML Model'\n",
    "tags = None\n",
    "model = remote_run.register_model(model_name = model_name, description = description, tags = tags)\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='inference/score.py')\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {'type': \"automl_classification\"}, \n",
    "                                               description = 'Heart Data Service')\n",
    "\n",
    "deploy_service_name = 'automl-model-deployment'\n",
    "service = Model.deploy(ws, deploy_service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "\n",
    "# Enable Application Insights\n",
    "service.update(enable_app_insights=True)\n",
    "\n",
    "print('Service State:', service.state, sep='\\n')\n",
    "print('Service Scoring URI:', service.scoring_uri, sep='\\n')\n",
    "print('Service Swagger URI:', service.swagger_uri, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "scoring_uri = aci_service.scoring_uri\n",
    "\n",
    "data = {\"data\":\n",
    "        [\n",
    "          { \n",
    "            \"age\": 80,\n",
    "            \"anaemia\": 1,\n",
    "            \"creatinine_phosphokinase\": 146,\n",
    "            \"diabetes\": 1,\n",
    "            \"ejection_fraction\": 20,\n",
    "            \"high_blood_pressure\": 0,\n",
    "            \"platelets\": 127000,\n",
    "            \"serum_creatinine\": 9.4,\n",
    "            \"serum_sodium\": 137,\n",
    "            \"sex\": 1,\n",
    "            \"smoking\": 1,\n",
    "            \"time\": 104\n",
    "          },\n",
    "          {\n",
    "            \"age\": 42,\n",
    "            \"anaemia\": 1,\n",
    "            \"creatinine_phosphokinase\": 111,\n",
    "            \"diabetes\": 0,\n",
    "            \"ejection_fraction\": 38,\n",
    "            \"high_blood_pressure\": 1,\n",
    "            \"platelets\": 87000,\n",
    "            \"serum_creatinine\": 0.8,\n",
    "            \"serum_sodium\": 116,\n",
    "            \"sex\":0,\n",
    "            \"smoking\": 0,\n",
    "            \"time\": 13\n",
    "          },\n",
    "      ]\n",
    "    }\n",
    "\n",
    "input_data = json.dumps(data)\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nService Logs:\\n\",service.get_logs())"
   ]
  },
  {
   "source": [
    "## Cleanup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "model.delete()\n",
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}